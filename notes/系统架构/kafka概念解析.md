# kafka概念解析

# 概述

kafka的三层消息结构：

- 主题层，每个主题可以配置 M 个分区，而每个分区又可以配置 N 个副本。
- 分区层：每个分区的 N 个副本中只能有一个充当领导者角色，对外提供服务；其他 N - 1个副本是追随者副本，只是提供数据冗余只用。
- 消息层：分区中包含若干条消息，每条消息的位移从 0 开始，依次递增。
- 最后，客户端程序只能与分区的领导者副本进行交互



## 分区

实现高可用的另一个手段就是备份机制（Replication）。备份的思想很简单，就是把相同的数据拷贝到多台机器上，而这些相同的数据拷贝在 Kafka 中被称为副本（Replica）。

Kafka 定义了两类副本：领导者副本（Leader Replica）和追随者副本（Follower Replica）。**前者对外提供服务，这里的对外指的是与客户端程序进行交互；而后者只是被动地追随领导者副本而已，不能与外界进行交互。**

副本的工作机制也很简单：生产者总是向领导者副本写消息；而消费者总是从领导者副本读消息。**至于追随者副本，它只做一件事：向领导者副本发送请求，请求领导者把最新生产的消息发给它，这样它能保持与领导者的同步。**

### Scalability

虽然有了副本机制可以保证数据的持久化或消息不丢失，但没有解决伸缩性的问题。伸缩性即所谓的 Scalability，是分布式系统中非常重要且必须要谨慎对待的问题。什么是伸缩性呢？我们拿副本来说，虽然现在有了领导者副本和追随者副本，**但倘若领导者副本积累了太多的数据以至于单台 Broker 机器都无法容纳了，此时应该怎么办呢？一个很自然的想法就是，能否把数据分割成多份保存在不同的 Broker 上**？

kafka就是这么做的，这种机制就是所谓的分区（Partitioning）。如果你了解其他分布式系统，你可能听说过分片、分区域等提法，比如 MongoDB 和 Elasticsearch 中的 Sharding、HBase 中的 Region，其实它们都是相同的原理，只是 Partitioning 是最标准的名称。**我们要注意副本是在分区这个层级上定义的。**

### 与数据库的对比

感觉kafka中分区的设计是很精华的，精华在哪里：**其实分区的作用就是提供负载均衡的能力，或者说对数据进行分区的主要原因，就是为了实现系统的高伸缩性（Scalability）。不同的分区能够被放置到不同节点的机器上，而数据的读写操作也都是针对分区这个粒度而进行的，这样每个节点的机器都能独立地执行各自分区的读写请求处理。并且，我们还可以通过添加新的节点机器来增加整体系统的吞吐量。**

用自己的话概括：分区就是为了实现负载均衡的能力，因为生产者和消费者都是直接和 leader 分区进行交互，分区又可以均衡地分布在broker集群中。

### 分区策略

首先我们可以通过 自定义 partitioner.class 参数来自定义分区策略，只要你自己的实现类定义好了 partition 方法，同时设置partitioner.class参数为你自己实现类的 Full Qualified Name，那么生产者程序就会按照你的代码逻辑对消息进行分区。

#### 轮询策略

比如一个主题下有 3 个分区，那么第一条消息被发送到分区 0，第二条被发送到分区 1，第三条被发送到分区 2，以此类推。当生产第 4 条消息时又会重新开始，即将其分配到分区 0，

轮询策略是 Kafka Java **生产者 API 默认提供的分区策略**。如果你未指定partitioner.class参数，那么你的生产者程序会按照轮询的方式在主题的所有分区间均匀地“码放”消息。

**轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是我们最常用的分区策略之一。**

#### 随机策略

 所谓随机就是我们随意地将消息放置到任意一个分区上

本质上看随机策略也是力求将数据均匀地打散到各个分区，但从实际表现来看，它要逊于轮询策略，所以如果追求数据的均匀分布，还是使用轮询策略比较好。事实上，随机策略是老版本生产者使用的分区策略，在新版本中已经改为轮询了。

#### 按消息键保存策略

Kafka 允许为每条消息定义消息键，简称为 Key。这个 Key 的作用非常大，它可以是一个有着明确业务含义的字符串，比如客户代码、部门编号或是业务 ID 等；也可以用来表征消息元数据。特别是在 Kafka 不支持时间戳的年代，在一些场景中，工程师们都是直接将消息创建时间封装进 Key 里面的。**一旦消息被定义了 Key，那么你就可以保证同一个 Key 的所有消息都进入到相同的分区里面，由于每个分区下的消息处理都是有顺序的，故这个策略被称为按消息键保序策略**

前面提到的 Kafka 默认分区策略实际上同时实现了两种策略：如果指定了 Key，那么默认实现按消息键保序策略；如果没有指定 Key，则使用轮询策略。

### 如何实现消息的顺序访问

我们假设消息生产的顺序和存储的顺序一致，即不会出现网络问题

#### 只用一个分区

理论上可行，但是失去了 kafka 的高吞吐量和负载均衡的优势。

#### 利用key

利用 key 可以做到消息的局部有顺序，即将对顺序性有要求的消息，使用  按消息键的分区策略，这样这部分对顺序性有要求的消息就会都保存在一个分区中并且是有序的。

## Broker

kafka 使用消息日志（Log）来保存数据，一个日志就是磁盘上一个只能追加写（Append-Only）消息的物理文件。因为只能追加写入，故避免了缓慢的随机 I/O 操作，**改为性能较好的顺序 I/O 操作，这是实现kafka 高吞吐量的一个重要手段。**

kafka删除消息：简单来说就是通过日志段（Log Segment）机制。在 Kafka 底层，一个日志又进一步细分成多个日志段，消息被追加写到当前最新的日志段中，当写满了一个日志段后，Kafka 会自动切分出一个新的日志段，并将老的日志段封存起来。

## 消费者组

首先要来了解下，为什么会有消费者组的概念，**主要是为了提升消费者端端吞吐量，多个消费者实力同时消费，加速这个那个消费端端吞吐量（TPS）**

再来看消费者组的概念：所谓的消费者组，指的是多个消费者实例共同组成一个组来消费一组主题。这组主题中的每个分区都只会被组内的一个消费者实例消费，其他消费者实例不能消费它，**这里的消费者实例可以是运行消费者应用的进程，也可以是一个线程，它们都称为一个消费者实例（Consumer Instance）。**

> 消费者组里面的所有消费者实例不仅“瓜分”订阅主题的数据，而且更酷的是它们还能彼此协助。假设组内某个实例挂掉了，Kafka 能够自动检测到，然后把这个 Failed 实例之前负责的分区转移给其他活着的消费者。这个过程就是 Kafka 中大名鼎鼎的“重平衡”（Rebalance）。嗯，其实既是大名鼎鼎，也是臭名昭著，因为由重平衡引发的消费者问题比比皆是。事实上，目前很多重平衡的 Bug 社区都无力解决。

每个消费者在消费消息的过程中必然需要有个字段记录他当前消费到了分区的那个位置上，**这个字段就是消费者位移（Consumer Offset），这里要注意和分区位移区分开，分区位移表征的是分区内的消息的位置，他是不变的，即一旦消息背词恒光写入到一个分区上，它的位移就是固定的了。而消费者位移则不同，它可能是随时变化的，毕竟它是消费者消费进度的指示器。****另外每个消费者有着自己的消费者位移（就和每个线程都是自己的程序计数器一样）**，因此一定要区分这两类位移的区别。