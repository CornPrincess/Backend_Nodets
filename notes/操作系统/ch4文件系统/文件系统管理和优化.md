# 文件系统管理和优化

## 磁盘空间管理 Disk-Space Management

存储n个字节的文字可以有两种策略：分配n个字节的连续磁盘空间，或者把文件分成很多个连续（或并不一定连续）的块。正如我们之前看到的，按连续字节序列存储文件有一个明显的问题：当文件扩大时，有可能需要在磁盘上移动文件。**因此，几乎所有的文件系统都把文件分割成固定大小的块来存储，个块之间不一定相邻。**

### 块大小 Block Size

拥有大的块因为这每个而文件都要占用一整个柱面，并且小文件会浪费大量的磁盘空间；小的块尺寸意味着大多数文件会跨越多个块，因此需要多次寻道与旋转延迟才能读出他们，从而降低了性能。

![block size](https://blog-1300663127.cos.ap-shanghai.myqcloud.com/BackEnd_Notes/operating%20system/blockSize.png)

从图中可以看出，磁盘的性能与空间利用率天生就是矛盾的，块越大，空间利用率越低，但是性能越好。从历史id角度看，文件系统将块大小设为1-4KB之间，但是随着磁盘超过了1TB，将块大小提升到了64KB。

### 记录空闲块 Keeping Track of Free Blocks

选定了块大小，下一个问题是如何跟踪空闲块

一种方法是使用磁盘块链表，每个块（空闲表）中包含尽可能多的空闲磁盘块号。对于1KB大小的块（空闲表）和32位的磁盘块号，空闲表中每个块包含有255个空闲块的号（需要有一个位置存放指向下一个块的指针）。他通常，采用空闲块存放空闲列表，这样存储器基本上是空的。

![keep track of free blocks](https://blog-1300663127.cos.ap-shanghai.myqcloud.com/BackEnd_Notes/operating%20system/keepTrackOfFreeBlock.png)

另一种方法是采用位图（bitmap），n个块的磁盘需要n位位图 。在位图中，空闲块用1表示，以分配块用0表示 

### 磁盘配额 Disk Quotas

多用户操作系统常常提供一种强制性的磁盘配额机制，其思想是管理员分给每个用户拥有文件和块的最大数量。

![disk quotas](https://blog-1300663127.cos.ap-shanghai.myqcloud.com/BackEnd_Notes/operating%20system/diskQuotas.png)

**这一方法有一种性质：即只要用户在退出系统前清除所超过的部分，他们就可以在一次中断会话期间超过其软限制（soft limits），但无论什么情况下都不能超过硬限制（hard limits）。**

## 文件系统备份 File-System Backups

- 只备份特定目录及其下的全部文件，而不是备份整个文件系统
- 对前一次备份以来没有更改过的文件再做备份是一种浪费，因此产生了**增量转储（incremental dumps）**的思想
- 考虑对备份文件流是否使压缩算法
- 对活动的文件系统做备份是很难的，因此记下文件系统的瞬时状态，即复制关键的数据结构，然后需要把将来对文件和目录所做的修改复制到块中
- 备份文件所引起的其他安全风险

转储磁盘到磁带上有两种方案：**物理转储（physical dump）和逻辑转储（logical dump）**

物理转储的主要优点是简单，快速。主要缺点是不能跳过选定的目录，也无法增量存储，还不能满足恢复个人文件的请求。正因如此，绝大多数配置都使用逻辑转储。

逻辑转储从一个或几个指定的目录开始，递归地转储其自给定基准日期后所更改的全部文件和目录。所以在逻辑转储中，转储磁带上会有一连串精心标识的目录和文件，这样就很容易满足回复特定文件或目录的请求。

## 文件系统的一致性 File-System Consistency

很多文件系统读取磁盘块，进行修改后再写回磁盘。**如果在修改过的磁盘全部写回之前系统崩溃，则文件系统很可能处于不一致的状态，如果一些未被写回的块是i节点、目录块或者是包含有空闲表的块时，这个额问题尤为严重。**

为了解决不一致（inconsistent）的问题，UNIX有 `fsck`，Windows有 `scandisk` 程序以检验文件系统的一致性，特别是崩溃之后的重新启动。**所有文件系统检验程序可以独立地检验每个文件系统（磁盘分区）的一致性**

一致性检查分为两种：块的一致性检查和文件的一致性检查。

### 块一致性

程序构造两张表，每张表中为每个块设立一个计数器，都初始化为0。第一个表的计数器跟踪该块在文件中出现的次数，数据从i节点中读出，第二个表的计数器跟踪该块在空闲表中的出现的次数，数据从空闲表中读出 。

![block consistency](https://blog-1300663127.cos.ap-shanghai.myqcloud.com/BackEnd_Notes/operating%20system/blockConsistency.png)

### 文件一致性

此时会用到一张计数器表，这时是一个文件对应于一个计数器，程序从根目录开始检验，沿着目录数递归下降，对于目录中的每个文件，将文件对应的计数器加1。当这个过程完成时，将每个文件对应计数器的数字与该文件i节点中的连接数目相比较。

**在MS-DOS和某些系统上，文件的删除仅仅是在对应目录或i节点上设置某一位，表明文件被删除，并没有把磁盘块返回到空闲表中，所以如果用户发现误删还可以运行特定的程序进行恢复。**

## 文件系统性能 File-System Performance

访问磁盘的速度比访问内存的速度慢很多，因此有几种方法用来改善性能

### 高速缓存 Caching

最常用的减少磁盘访问次数技术是**块高速缓存（block cache）**或者**缓冲区高速缓存（buffer cache）**高速缓存在逻辑上是一系列的块，他们在逻辑上属于磁盘，但实际上基于性能的考虑放在内存中。

管理高速缓存常用的算法为：检查全部的读请求，查看在高速缓存中是否有所需要的块。如果存在，可执行读操作而无序访问访问磁盘。如果该块不在高速缓存中，则首先把 它读到高速缓存中，再复制到需要的地方。

需要快速判断块是否在高速缓存中，常用的方法为把磁盘地址进行**散列**操作。

![buffer cache](https://blog-1300663127.cos.ap-shanghai.myqcloud.com/BackEnd_Notes/operating%20system/bufferCache.png)

如果高速缓存已满，那么此时就可以用到LRU算法，我们可以在图中看到，双向链表将最近使用的块放在链尾，而最少使用的块放在表头。

现在如果一个关键块读入了缓存并做了修改但是没有写回磁盘。这是，系统崩溃导致文件不一致。把i节点放在链尾，此时需要相当长一段时间走到链头被重写如磁盘，因此要做如下修改：

- 这一块是否不久后会被用到
- 这一块是否关系到文件一致性

因此可以将块分为i节点块，间接块（indirect blocks）、目录块、满数据块和部分数据块。把有可能最近不在需要的块放在链表前部，对很快将会用到的块，如数据块，放在链表尾部。

如果关系到文件系统一致性的该块被修改，应该立即写入磁盘。

**但我们有时不希望数据块在缓存中放太久，比如编辑文档时突然崩溃，此时数据在数据块中，而数据块在高速缓存中，将会丢失工作数据，对于这种情况，UNIX提供了 sync 系统调用，它强制把全部修改过的块立即写回磁盘。系统运行时，后台运行一个通常名为update的程序，它无限循环不断执行sync调用，每次间隔30s。**

**Windows采用一个等价的系统调用，FlushFileBuffers,， 其做法是，只要被写进高速缓存，就把每个被修改的块写进磁盘。将缓存中所有被修改的块立即写回磁盘称为通写高速缓存（write through cache），不过这需要更多的磁盘IO。**

### 块提前读 Block Read Ahead

**在需要用到块之前，试图提前将其写入高速缓存，从而提高命中率。但块提前读策略值适合顺序读取的文件，对随机存取文件，提前读不起作用。**

### 减少磁盘臂运动 Reducing Disk-Arm Motion

将有可能顺序存取的块放在一起，当然是最好在一个柱面（cylinder）上



## 磁盘碎片整理 Defragmenting Disks

在初始安装操作系统后，从磁盘的开始位置，一个接一个地连续安装了程序和文件。所有的空闲磁盘空间放在一个单独的、与被安装的文件临近的单元里。但随着时间的流逝，文件不断地被删除创建，会产生很多碎片，此时新建的文件会散布在磁盘上，造成性能的降低。

磁盘性能可以通过如下方式回复：**移动文件使他们相邻，并把所有的（至少大部分）的空闲空间放在一个或多个大的连续的区域内。Windows有一个程序 `defrag` 就是做这个工作的。**

Linux文件系统（特别是ext2和ext3）选择磁盘块（disk block）的方式。固态硬盘不需要进行碎片清理，而且清理了反而会影响其寿命。