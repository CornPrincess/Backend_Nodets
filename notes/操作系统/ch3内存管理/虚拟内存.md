# 虚拟内存 Virtual Memory

尽管基址寄存器（base register）和界限寄存器（limit register）可以用来创建地址空间（address space）的抽象，还存在另一个问题：管理软件的膨胀（bloatware）。

当现代软件对运行内存要求越来越高时，交换技术（swapping）就不是一项有吸引力的技术，因为一个传统的SATA硬盘的峰值传输速率最高可以有几百MB/s， 这意味着至少需要几秒才能换出1G的程序，并需要另一个几秒才能将1G的程序换入。

**虚拟内存的基本思想是:每个程序有自己的进程空间，这个空间被分割成多个块，每一个块称为一页或页面（page），每一页有连续的地址范围。这些页被映射到物理内存，但并不是所有的页都必须在内存中才能运行程序。**当程序引用到一部分在物理内存中的地址空间时，由硬件立即执行必要的映射。当程序引用到一部分不在物理内存中的地址空间时，有操作系统负责将确实的部分装入物理内存并重新执行失败的指令。

虚拟内存可以是的整个地址空间可以用相对较小的单元映射到物理内存，而不是为正文段（text）和数据段（data）分进行重定位。

**虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中，当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。**

## 分页 Paging

在任何一台计算机上，程序引用了有一组内存地址，地址可以通过索引（index），基址寄存器（base register），段寄存器（segment register）或其他方法来产生。

由程序产生的这些地址成为虚拟地址（virtual address），他们构成了一个虚拟地址空间（virtual address space），在没有虚拟内存的计算机上，系统直接将虚拟地址送到内存总线上，读写操作使用具有地址的物理内存字；而使用虚拟内存的情况下，**虚拟地址不是被直接送到内存总线（memory bus）上，而是被送到内存管理单元（memory management unit， MMU），MMU把虚拟地址映射为物理内存地址。**

![paging](https://blog-1300663127.cos.ap-shanghai.myqcloud.com/BackEnd_Notes/operating%20system/paging.png)

虚拟内存地址空间按照固定大小划分成称为页面（page）的若干单元。在物理内存中对应的单元称为页框（page frame），页面和页框的大小通常是一样的。RAM和磁盘之间的交换总是以整个页面为单元进行的。

当程序访问了一个未映射的页面时，MMU注意到该页面没有被映射，于是使CPU陷入到操作系统，这个陷阱（trap）称为缺页中断（page fault）。操作系统找到一个很少使用的页框并把它的内容写入磁盘（如果它不在磁盘上），随后把需要访问的页面读到刚才回收的页框中，修改映射关系，然后重新启动引起陷阱的指令。

## 页表 Page Tables

**作为最简单的实现，虚拟地址到物理地址的映射可以概括如下：虚拟地址被划分成虚拟页号（virtual page number）（高位部分）和偏移量（offset）（地位部分）。例如，对于16位地址和4KB 的页面大小，高4位可以指定16个虚拟页面中的一页，而低12位接着确定了所选页面中的字节偏移量（0-4095）**，用其他的数字拆分也行，不同的划分对于不同的页面大小。

**虚拟页号可作为页表的索引，以找到该虚拟页面对于的页表项，由页表项可以找到页框号，然后把页框号拼接到偏移量的最高位，以替换调虚拟页号，形成送往内存的物理地址。**

**在深入到更多应用实现问题之前，值得再次强调的是：虚拟内存本质上是用来创造一个新的抽象概念——地址空间，这个概念是对物理内存的抽象，类似于进程是对物理机器（CPU），虚拟内存的实现，是将虚拟地址空间分解成页，并将每一页映射到物理内存的某个页框或者（暂时）解除映射。**



## 加速分页过程

在任何分页式系统中，都需要考虑两个主要问题：

- 虚拟地址到物理地址的映射必须非常快
- 如果虚拟地址空间很大，页表也会很大

第一个问题是由于每次访问内存都需要进行虚拟地址到物理地址到映射，所有的指令最终都必须来内存，并且很多指令也会访问内存中的操作树。因此，每条指令进行一两次或更多页表访问是必要的。如果执行一条指令需要1ns，页表查询必须在0.2ns之内完成，避免映射称为一个主要瓶颈。

第二个问题来自现代计算机使用至少32位的虚拟地址，64位也很多。一台可用产生16位地址的计算机，地址范围从0到64K-1（2的16次方），且这些地址是虚拟地址。而32位的计算机可用有2的32次方（4GB）个地址空间，如果页面大小为4KB， 那么可以有1048576(约100万)个页面，那么页表必然有100万条表项。每个进程都有自己的页表。

对大而快速的页映射的需求成为了构建计算机的虫咬约束。最简单的设计是由一组快速硬件寄存器（fast hardware Register）组成的单一页表，每一个表项对应一个虚页，虚页号作为索引。当启动一个进程时，操作系统把保存在内存中的进程页表的副本载入到寄存器中。在进程运行过程中，不必再为页表而访问内存。

优点：

- 简单，在映射过程中不需要访问内存

缺点：

- 当页表很大时，代价高昂，而且每一次上下文切换都必须装载整个页表，这样会降低性能，在大部分时间都不适用

另一个极端做法是将整个页表都在内存中。这是需要的硬件是仅仅是一个指向页表起始位置的寄存器

优点：

- 这样的设计使得进行上下文切换时，进行虚拟地址到物理地址的映射只需要重新装入一个寄存器。这样做法

缺点：

- 在执行每条指令时，都需要一次或多次访问内存，以完成页表项的读入，速度非常慢。

现在来讨论加速分页技术。

### 转换检测缓冲区 Translation Lookaside Buffers

大多数技术都是从内存中的页表开始的。**在不分页的情况下，这条指令只访问一次内存，即从内存中取指令。有了分页后，至少要多访问一次内存：获取页表。因此执行速度通常被CPU从内存中取指令和数据的速度所限制。**所以分页时会降低系统一半的内存，这种情况下没人会使用分页。

计算机的设计者已经找了解决方案，这个方案基于一种现象：**大多数程序总是对少量的页面进行多次的访问，而不是相反的。因此，只有很少的页表项会被反复读取，而其他页表项很少被访问。**

**这种解决方案是给计算机设置一个小型的硬件设备，将虚拟地址直接映射到物理地址，而不必再访问页表。**这种设备成为**转换检测缓冲区（Translation Lookaside Buffer， TLB）**，有时也称为**相联存储器（associate memory）**它通常在MMU中，包含少量的表项，通常不会超过256个。

![TLB](https://blog-1300663127.cos.ap-shanghai.myqcloud.com/BackEnd_Notes/operating%20system/TLB.png)

现在来看下**TLB**如何工作：将一个虚拟地址放入MMU中进行转换时，硬件先通过将该虚拟页号与TLB中所有表项同时（simultaneously）进行匹配，判断虚拟页面是否在其中，**如果发现了一个有效的匹配并且要进行的访问操作不违反保护位，则将页框号直接从TLB中取出而不必再访问页表，如果操作不符合保护位，则产生一个保护错误，就像对页表进行非法访问一样。**

**当虚拟页号不在TLB中时，MMU检测到没有有效的匹配项时，会进行正常的页表查询，接着从TLB中淘汰一个表项，然后用新的页表项代替它。这样，如果这以页面很快再被访问，第二次访问TLB时自然就会命中而不是不命中。当一个页表项被清除出TLB时，将修改位复制到内存中的页表项，其他值不变。当页表项中从页表装入TLB时，所有值来自内存。**

### 软件TLB管理 Software TLB Management

到目前位置，我们已经假设每一台具有虚拟内存的机器都具有由硬件识别的页表，以及一个**TLB**。在这种设计中，对TLB的管理和TLB的失效处理都完全由MMU硬件来实现，只有在内存中没有找到这个页面时（发送缺页中断），才会陷入到操作系统中。

但在现代的RISC机器，几乎所有的页面管理都是在软件中实现的。在这些机器中，TLB表项被操作系统显示地装载。**当发生TLB访问失效，不再是由MMU到页表中查找并取出需要的表项，而是生成一个TLB失效并将问题交给操作系统解决。系统必须先找到该页面，然后从TLB中删除一个项，接着装载一个新的项，最后在执行先前出错的指令。当然，所有 的这一切都必须在有限的几条指令中完成，因为TLB失效比缺页中断发生的更加频繁。**

**如果TLB大到可以减少失效率时，TLB的软件管理就会变得足够有效，这种方法的主要好处是获得了一个非常简单的MMU，这就在CPU芯片上为高速缓存以及其他改善性能的设计腾出了相当大的空间。**

> A soft miss occurs when the page referenced is not in the TLB, but is in memory. **All that is needed here is for the TLB to be updated. No disk I/O is needed. Typically a soft miss takes 10–20 machine instructions to handle and can be completed in a couple of nanoseconds. In contrast, a hard miss occurs when the page itself is not in memory (and of course, also not in the TLB). A disk access is required to bring in the page, which can take several milliseconds, depending on the disk being used.** A hard miss is easily a million times slower than a soft miss. Looking up the mapping in the page table hierarchy is known as a page table walk

> Actually, it is worse that that. A miss is not just soft or hard. Some misses are slightly softer (or slightly harder) than other misses. For instance, suppose the page walk does not find the page in the process’ page table and the program thus incurs a page fault. There are three possibilities**. First, the page may actually be in memory, but not in this process’ page table. For instance, the page may have been brought in from disk by another process. In that case, we do not need to access the disk again, but merely map the page appropriately in the page tables. This is a pretty soft miss that is known as a minor page fault. Second, a major page fault occurs if the page needs to be brought in from disk. Third, it is possible that the program simply accessed an invalid address and no mapping needs to be added in the TLB at all. In that case, the operating system typically kills the program with a segmentation fault. Only in this case did the program do something wrong.** All other cases are automatically fixed by the hardware and/or the operating system—at the cost of some performance

## 针对大内存页表

在原有的内存页表的方案商，引入快表（TLB）可以用来加快虚拟地址到物理地址的转换。不过这不是唯一需要解决的问题，**另一个问题是怎样处理巨大的虚拟地址空间，下面讨论两种解决方法。**

### 多级页表 Multilevel Page Tables

如图，32位的虚拟地址被划分为10为的PT1域，10位的PT2域和12为的Offset（偏移量）域，因为偏移量是12位，所以页面长度为4KB，共有2<sup>20</sup>个页面。

引入多级页表的概念是避免把全部页表一直保存在内存中，特比是那些从不需要的页表就不应该保留。比如一个需要12MB内存的进程，其最低端是4MB的程序正文段，后面是4MB的数据段，顶端是4MB的堆栈端，在数据段上方和堆栈端下方是大量根本没有使用的空闲段。

整个4GB（32位）虚拟地址空间已经被分成1024个4MB的块，所以这1024个表项中的每一个都表示4MB的虚拟地址空间。当一个虚地址被送到MMU时，MMU首先提取PT1域并把该值作为访问顶级页表的索引 。

![multilevel Page Tables](https://blog-1300663127.cos.ap-shanghai.myqcloud.com/BackEnd_Notes/operating%20system/multilevelPageTable.png)

### 倒排页表 Inverted Page Tables

对于64位计算机，如果现在地址空间是2<sup>64</sup>字节，页面大小为4KB，那么需要2<sup>52</sup>个表项的页表，如果每个表项是8个字节，那么整个页表需要32PB，因此我们需要不同的方案。

在倒排页表的设计中，在实际内存中每一个页框有一个表项，而不是每一个虚拟页面有一个表项，例如，对弈4KB的页面，4GB的 RAM，一个倒排页表仅需要2<sup>20</sup>个表项。

虽然倒排页表节省了大量空间，但它也有严重的不足：从虚拟地址到物理地址的转换会变得很困难，**当进程n访问虚拟页面p时，硬件不在能通过把p当做指向页表的一个所以来查找物理页框。取而代之的 是它必须搜索整个倒排页表来查找某一个表项，该搜索必须对每一个内存访问操作都执行一次，而不仅仅是在发送缺页中断时执行。**

解决的办法是使用TLB。如果TLB能够记录所有频繁使用的页面，地址转换就可能变得像通常的页表一样快。但是，发生TLB失效时，需要用软件来搜索整个倒排页表。一个可行的实现该搜索的方法是建立一张散列表，用虚拟地址来散列，当前所有在内存中的具有相同散列值的虚拟页面被链接在一起。

倒排页表在64位机器中很常见。

![interved page table](https://blog-1300663127.cos.ap-shanghai.myqcloud.com/BackEnd_Notes/operating%20system/interved%20page%20table.png)