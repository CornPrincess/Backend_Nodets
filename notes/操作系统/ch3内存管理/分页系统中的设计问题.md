# 分页系统中的设计问题

## 局部分配策略与全局分配策略 Local versus Global Allocation Policy

与页面置换有关的是，发送缺页故障时，置换本进程的页面还是其他进程的页面，即怎样在相互竞争的可运行程序之间分配内存。

![local versus global allocation policy](https://blog-1300663127.cos.ap-shanghai.myqcloud.com/BackEnd_Notes/operating%20system/local%20versus%20global%20page%20replacement.png)

图b算法为局部（local）页面置换算法，图c为全局（global）页面置换算法，局部算法可以有效地为每个进程分配固定的内存片段，全局算法在可运行的进程之间动态地分配页框。因此分配给各个进程的页框数是随时间变化的。

全局算法在可运行进程之间动态地分配页框，因此分配给各个进程的页框数是随时间变化的，全局算法在通常情况下工作得比局部算法好。若使用局部算法，即使有大量的空闲页框存在，工作集的增长也会导致颠簸（ thrashing ），如果工作集变小，局部算法又会浪费内存。

可以使用为进程分配页框的算法，其中一种方法是定期确定进程运行的数目并为他们分配等额的份额。可以按照进程的大小比例来分配相应数目的页面，对每个进程规定一个最小的页框数，这样无论多么小的进程都能运行。

如果使用全局算法，根据进程的大小按比例分配页面也是可能的，**但是该分配必须在程序运行时动态更新，这里的方法用到了（Page Fault Frequency PFF）缺页中断率算法。它指出了何时增加或减少分配给一个进程的页面，但却完全没有说明在发送缺页中断时应该替换掉哪一个页面，它仅仅控制分配集的大小。**

缺页中断率会随着分配的页面增加而降低，这是**PFF**背后的假定。

**值得注意的是，一些页面置换算法既适用于局部置换算法，有适用于全局置换算法，如FIFO，LRU。另一方面，对于其他的页面置换算法，只有采取局部策略才有意义，如工作集和WSClock算法，是针对某些特定进程的而且必须应用在这些进程的上下文中。**

![local versus global replacement](https://blog-1300663127.cos.ap-shanghai.myqcloud.com/BackEnd_Notes/operating%20system/PFF.png)

## 负载控制 Load Control

即使是使用了最优页面置换算法并对进程采用理想的全局页框分配，系统也可能产生颠簸。事实上，一旦所有进程的组合工作集超出了内存容量，就可能发生颠簸。该现象的症状之一就是如**PFF**算法所指出的，一些进程需要更多的内存，但是没有进程需要更少的内存，在这种情况下，没有方法能够在不影响其他进程的情况下满足那些需要更多内存的进程的需要。唯一现实的方案就是暂时从内存中去掉一些进程。

减少竞争内存的进程数的一个好方法是将一部分进程交换到次哦安，并释放他们所占有的所有页面。例如，一个进程可以被交换到磁盘，而它的页框可以被其他处于颠簸状态的进程分享，如果颠簸停止，系统能够这样运行一段时间，如果颠簸没有停止，需要继续将其他进程交换出去，直到颠簸结束。因此，即使是使用分页，交换也是需要的，只是现在交换是用来减少对内存潜在的需求，而不是收回它的页面。

将进程交换出去以减轻内存需要的压力是借用了两级调度（two level scheduling）的思想，在此过程中，一些进程被放到磁盘，此时用一个短期的调度程序来调度剩余的进程。很明显，这两种思路可以被组合起来，将恰好足够的进程交换出去以获取可接受的缺页中断率，一些进程被周期性地从磁盘掉入，而其他一些则周期性的交换到磁盘。

不过，另一个需要考虑的因素是多道程序设计的道数，当内存中的进程数太低时，CPU可能在很长的时间处于空闲状态，考虑到该因素，在决定交换出哪个程序时不光要考虑进程大小和分页率，还要考虑它的特性（CPU密集型还是IO密集型）（CPU bound， IO bound）

## 页面大小 Page Size

页面大小是操作系统可供选择的一个参数，即使硬件设计只支持512字节的页面，操作系统 也很容易通过总是为页面对0和1，2和3等分配连续的512字节的页框，而将其作为1KB的页面。

要确定最佳的页面大小，需要在几个互相矛盾的因素之间选择权衡，有两个因素可以作为选中小页面的理由：

- 随便选中一个正文段，数据段或堆栈段很可能不会恰好装满整个页面，平均的情况下，最后的一个页面中有一半是空的。多余的空间浪费了，这种浪费称为**内部碎片（internal fragmentation）**，在内存中有n段，页面大小为p字节时，会有np/2 字节被内部碎片浪费。从这方面考虑，使用小页面更好。
- 考虑一个程序分为8个阶段执行，每个阶段需要4KB内存，如果页面大小是32KB，那就必须给该进程分配32KB内存。但如果页面大小为4KB或更小，在任何时刻它只需要4KB内存。总得来说，与小页面相比，大页面使更多没有用的程序保留在内存中。

小页面不好地方

- 程序需要更多的页面，即需要更大的页表。**内存与磁盘之间的传输一般是一次一页，传输中的大部分时间都花在了寻道（seek）和旋转延迟（rotational delay）上，所以传输一个小的页面和 传输一个大的页面基本上一样的。**

从数学上分析，假设进程平均大小是 `s` 个字节，页面大小是 `p` 个字节，每个页表项需要 `e` 个字节。那么每个进程需要的页数大约是 `s/p` ，占用了 `se/p` 个字节的页表空间。内部碎片在最后一页浪费的内存是 `p/2` 。因此，由页表和内部碎片损失造成的全部开销是一下两项之和。
$$
开销 = se / p + p / 2
$$


通过求导可得，最优页面大小公式为

$$
p = \sqrt{2se}
$$


例如， s = 1 MB， e = 8 bytes，最优页面大小是4 KB。商业计算机页面大小一般是512 bytes 到64KB之间，现在较常见的大小为4 KB 或 8 KB。

## 分离的指令空间和数据空间 Separate Instruction and Data Spaces

大多数计算机只有一个地址空间，既存放程序也存放数据。通常地址空间太小了，一种解决方案是，为指令（instruction）（程序正文 program text）和数据分离地址空间，分别为I空间和D空间，每个地址空间都从0到最大值。连接器（linker）必须知道何时使用分离的I空间和D空间。

在使用这种设计的计算机中，两种地址空间都是可以进行分页，而且互相独立。他们分别有自己的页表，分别完成虚拟页面到物理页框的映射。

![separate I and D spaces](https://blog-1300663127.cos.ap-shanghai.myqcloud.com/BackEnd_Notes/operating%20system/separate%20I%20and%20D%20spaces.png)

## 共享页面 Shared Pages

在大型多道程序系统中，几种不同的用户同时运行同一个程序是很常见的，显然避免了在内存中与一个页面的两个副本，共享页面效率更高，但不是所有的页面都能共享，哪些只读的可以，但是数据页面不能共享。

如果系统支持分离的I空间和D空间，那么让多个进行来共享程序就变得很简单了，这些进程使用共同的I空间页表和不同的D空间页表。在比较典型的实现中，每个进程在它的进程表中都有两个指针：一个指向I空间，一个指向D空间

![shared page](https://blog-1300663127.cos.ap-shanghai.myqcloud.com/BackEnd_Notes/operating%20system/sharedPages.png)

只要这两个进程都仅仅是读数据，这种情况就可以保持下去，当一个进程更新了一点数据，就会触发只读保护，并引发操作系统陷阱，然后会生成一个该页的副本，这样每个进程都有自己的专用副本。两个复制都是可以读写的，随后对任何一个副本的写到做都不会在引发陷阱。这种策略意味着那些从来不会执行写操作的页面是不需要复制的，只有实际修改的数据页面需要复制。这种方法称为**写时复制（copy on write）**，它通过减少复制而提高了性能。

## 共享库 Shared Libraries

可以使用其他的**粒度（granularities）**取代单个页面来实现共享。如果一个程序被启动两次，大多数操作系统会走到共享所有的代码页面，而在内存中值保留一份代码页面的副本。代码页面总是只读的。

现代操作系统中，有很多大型的库被众多进程使用，把所有这些库静态地与磁盘上的每一个可执行程序绑定一起，将会使他们变得更加庞大，一种更通用的技术是使用**共享库（shared libraries）（在windows中称为DLL或动态链接库 Dynamic Link Libraries）**

任何在 `.o` 目标文件中被调用了但是没有被定义的函数（比如printf）都被称作**未定义外部函数（undefined externals）**。连接器会在库中寻找这些未定义外部函数，任何被这些未定义外部函数调用了但是不存在的函数也会称为未定义外部函数。例如 printf 需要write， 但是write还没有被加载进来，链接器会查找write并把它加载进来。但连接器完成任务后，一个可执行二进制文件被写进磁盘，其中包括了所需的全部函数。

**静态链接上百个这些库的程序会浪费大量的磁盘空间，在装载这些程序时也会浪费大量的内存空间，因为系统不知道它可以共享这些库，这就是引入共享库的原因。**

**当一个程序与共享库链接时，连接器没有加载被调用的函数，而是加载了一小段能够在运行时绑定被调用函数的存根例程（stub routine）**。**依赖于配置信息，共享库或者和程序一起被装载，或者在其所包含函数第一次被调用时被装载。当然，如果其他程序已经装载了某个共享库，就没有必要再次装载它了——这正是关键所在。值得注意的是，当共享库被装载和使用时，整个库并不是被一次性读入内存，而是根据需要，以页面为单位装载的，因此没有被调用的函数是不会装载到内存中的。**

因此共享库的优点有：

- 是可执行文件变小，节省内存空间
- 如果共享库的一个函数因为修正一个bug更新了，那么并不需要重新编译调用了这个函数的程序。

不过共享库也有必须解决的问题，当两个进程使用共享库，但这个库被定位在不同的地址上。假设共享库第一件要做的事就是跳转到地址16，如果这个库没被共享，那么可在装载的过程中重定位，但是共享就不能这么做。

![shared library](https://blog-1300663127.cos.ap-shanghai.myqcloud.com/BackEnd_Notes/operating%20system/sharedLibrary.png)

解决方法有两种。

- **写时复制（copy on write）**，并为每个共享这个库的进程创建新页面，在创建新页面的过程中进行重定位，但是这与共享库的目的相悖。
- 更好的方法是，在编译共享库时，用一个特殊的编译选项告诉编译器，不要产生使用绝对地址的指令。相反，只能产生使用相对地址的指令。**只使用相对偏移量的代码称作位置无关代码（position-independent code）**

## 内存映射文件 Mapped Files

**共享库实际上是一种更为通用的机制——内存映射文件（memory-mapped files）的一种特例。这种机制的思想是：进程可以通过发起一个系统调用，将一个文件映射到其虚拟地址空间的一部分。**

在多数的实现中，在映射共享的页面时不会实际读入页面的内容，而是在访问页面时才会被每次一页地读入，磁盘文件则当做后备存储昂进程退出或显示的解除文件的映射时，所有被改动的页面会被写回到文件中。

如果两个或两个以上的进程同时映射了同一个文件，他们就可以通过共享内存来通信。很显然，如果内存映射文件可用，共享库就可用使用这个机制。

## 清除策略 Cleaning Policy

如果发送缺页中断时系统有大量的空闲页框，此时分页系统工作在最佳状态。如果每个页框都被占用，而且被修改过的话，再换入一个新页面时，旧页面应该首先被写回磁盘。

**为保证有足够的空闲页框，很多分页系统有一个称为分页守护进程（paging daemon）的后台进程。它在大多数时候睡眠，但定期被唤醒检查内存的状态。如果空闲页框过少，分页守护进程通过预定的页面置换算法选中页面换出内存，如果这些页面装入内存后被修改过，则将他们写回磁盘。**

保存一定数目的页框供给比使用所有内存并在需要时搜索一个页框有更好的性能，分页守护进程至少保证了所有的空闲页框是“干净”的，所以空闲页框在被分配时不必再急着写回磁盘。

## 虚拟内存接口 Virtual Memory Interface

对于一些高级系统，程序员可以对内存映射（memory map）进行控制，并通过非常规的方法来增强程序的行为。

允许程序员对内存映射进行控制的一个原因就是为了允许两个或多个进行共享通一部分内存。如果程序员可以对内存区域命名，那么就有可能实现共享内存，通过两个进程共享同意部分页面，高带宽的共享就称为可能——一个进程王共享内存中写内容而另一个从中读取内容。

页面共享页可以用来实现高性能的消息传递系统（high performance message-passing system）。

另一种高级春初管理技术是分布式共享内存（distributed shared  memory）

